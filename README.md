# Reconocimiento-de-emociones-con-machine-learning

Documentacion 

 
SECCI√ìN 1: Librer√≠as
import os  # Para trabajar con archivos y directorios (listar carpetas, construir rutas)
import librosa  # Para cargar y analizar archivos de audio (especialmente en tareas de Machine Learning)
import numpy as np  # Librer√≠a para c√°lculos num√©ricos y arreglos (vectores y matrices)
import sounddevice as sd  # Para grabar audio directamente desde el micr√≥fono
import soundfile as sf  # Para guardar audio grabado en un archivo .wav
from sklearn.model_selection import train_test_split  # Para dividir datos en entrenamiento y prueba
from sklearn.preprocessing import LabelEncoder, StandardScaler  # Para codificar etiquetas y escalar datos num√©ricos
from sklearn.svm import SVC  # El modelo SVM (Support Vector Machine) para clasificaci√≥n
from sklearn.metrics import classification_report  # Para obtener m√©tricas del modelo (precisi√≥n, recall, F1)
import matplotlib.pyplot as plt  # Para graficar los resultados
import joblib  # Para guardar y cargar el modelo ya entrenado
________________________________________
SECCI√ìN 2: Par√°metros y rutas
DATASET_PATH = r"C:\Users\macaj\Downloads\Banco de Audio"  # Ruta donde est√°n las carpetas con audios
EMOTIONS = {
    'feliz': 'feliz',
    'triste': 'triste',
    'enojo': 'enojo',
    'miedo': 'miedo'
}
Diccionario para mapear nombres de carpetas a emociones. Las carpetas deben llamarse ‚Äúfeliz‚Äù, ‚Äútriste‚Äù, etc.
MODEL_FILENAME = "emotion_svm_model.joblib"  # Nombre del archivo donde se guarda el modelo entrenado
SCALER_FILENAME = "emotion_scaler.joblib"  # Archivo donde se guarda el escalador (StandardScaler)
LABELENCODER_FILENAME = "emotion_label_encoder.joblib"  # Archivo del codificador de etiquetas (LabelEncoder)

DURATION = 3  # Duraci√≥n del audio a grabar o cargar (en segundos)
SR = 22050  # Frecuencia de muestreo del audio (t√≠pico en an√°lisis de voz)
________________________________________
 SECCI√ìN 3: Extracci√≥n de caracter√≠sticas
def extract_features_from_file(file_path):
    audio, sr = librosa.load(file_path, sr=SR, duration=DURATION, offset=0.5)
    mfcc = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=40)
    return np.mean(mfcc.T, axis=0)
‚Ä¢	Carga un archivo de audio.
‚Ä¢	Calcula los coeficientes MFCC (Mel Frequency Cepstral Coefficients), que resumen c√≥mo suena la voz.
‚Ä¢	Retorna el promedio de esos coeficientes como un vector.
def extract_features_from_array(audio_array, sr):
    mfcc = librosa.feature.mfcc(y=audio_array, sr=sr, n_mfcc=40)
    return np.mean(mfcc.T, axis=0)
‚Ä¢	Igual que la funci√≥n anterior, pero trabaja con audio en forma de array (grabado en tiempo real).
________________________________________
SECCI√ìN 4: Grabaci√≥n desde micr√≥fono
def record_from_microphone(duration=DURATION, sr=SR):
    print(f"‚è∫ Grabando {duration} segundos... Presiona Ctrl+C para cancelar.")
    try:
        recording = sd.rec(int(duration * sr), samplerate=sr, channels=1, dtype='float32')
        sd.wait()
        return np.squeeze(recording)
    except Exception as e:
        print(f"Error al grabar desde el micr√≥fono: {e}")
        return None
‚Ä¢	Graba audio durante 3 segundos.
‚Ä¢	sd.rec graba y sd.wait() espera a que termine.
‚Ä¢	np.squeeze convierte el array de 2D a 1D.
________________________________________
SECCI√ìN 5: Entrenamiento del modelo
def train_and_save_model():
    features = []
    labels = []
‚Ä¢	features: lista de vectores MFCC.
‚Ä¢	labels: lista con las emociones correspondientes.
    for emotion_dir in os.listdir(DATASET_PATH):
        emotion_key = emotion_dir.lower()
        if emotion_key in EMOTIONS:
            emotion_path = os.path.join(DATASET_PATH, emotion_dir)
‚Ä¢	Recorre las carpetas del dataset.
‚Ä¢	Si el nombre de la carpeta est√° en el diccionario, entra.
            for file in os.listdir(emotion_path):
                if file.endswith(".wav") or file.endswith(".mp3"):
                    file_path = os.path.join(emotion_path, file)
‚Ä¢	Busca archivos .wav o .mp3 dentro de cada carpeta de emoci√≥n.
                    try:
                        mfcc = extract_features_from_file(file_path)
                        features.append(mfcc)
                        labels.append(EMOTIONS[emotion_key])
                    except Exception as e:
                        print(f"‚ö† Error al procesar {file_path}: {e}")
‚Ä¢	Extrae los MFCC y los guarda junto con su etiqueta.
‚Ä¢	Si hay error, lo muestra.
    X = np.array(features)
    y = np.array(labels)
‚Ä¢	Convierte listas a arreglos NumPy.
    label_encoder = LabelEncoder()
    y_encoded = label_encoder.fit_transform(y)
‚Ä¢	Convierte las etiquetas (‚Äòfeliz‚Äô, ‚Äòenojo‚Äô, etc.) en n√∫meros.
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)
‚Ä¢	Normaliza los datos para que todas las caracter√≠sticas tengan media 0 y varianza 1.
    X_train, X_test, y_train, y_test = train_test_split(
        X_scaled, y_encoded, test_size=0.2, random_state=42
    )
‚Ä¢	Divide el dataset: 80% para entrenar, 20% para probar.
    model = SVC(kernel='linear', probability=True)
    model.fit(X_train, y_train)
‚Ä¢	Crea y entrena un clasificador SVM lineal.
    y_pred = model.predict(X_test)
    print("\n=== REPORT DE EVALUACI√ìN EN TEST ===")
    print(classification_report(y_test, y_pred))
‚Ä¢	Predice y muestra el rendimiento del modelo.
    joblib.dump(model, MODEL_FILENAME)
    joblib.dump(scaler, SCALER_FILENAME)
    joblib.dump(label_encoder, LABELENCODER_FILENAME)
‚Ä¢	Guarda el modelo, el escalador y el codificador de etiquetas en disco.
    plot_classification_report(y_test, y_pred, label_encoder)
‚Ä¢	Muestra una gr√°fica de desempe√±o por emoci√≥n.
________________________________________
SECCI√ìN 6: Gr√°fico de F1-Score
def plot_classification_report(y_true, y_pred, label_encoder):
    report = classification_report(y_true, y_pred, output_dict=True)
    emotions = [k for k in report.keys() if k not in ('accuracy', 'macro avg', 'weighted avg')]
    f1_scores = [report[e]['f1-score'] for e in emotions]
    emotion_names = label_encoder.inverse_transform([int(e) for e in emotions])
‚Ä¢	Calcula el F1-score por emoci√≥n.
‚Ä¢	Convierte los √≠ndices num√©ricos a etiquetas de emoci√≥n.
    plt.figure(figsize=(8, 4))
    plt.bar(emotion_names, f1_scores, color='skyblue')
    plt.ylim(0, 1)
    plt.title('Precisi√≥n por clase (F1-Score)')
    plt.xlabel('Emoci√≥n')
    plt.ylabel('F1-Score')
    plt.tight_layout()
    plt.show()
‚Ä¢	Crea y muestra una gr√°fica de barras del rendimiento por clase.
________________________________________
SECCI√ìN 7: Predicci√≥n en tiempo real
def predict_emotion_from_microphone():
    if not (os.path.exists(MODEL_FILENAME) and os.path.exists(SCALER_FILENAME) and os.path.exists(LABELENCODER_FILENAME)):
        print("‚ö† No se encontraron todos los archivos necesarios. Entrenando primero...")
        train_and_save_model()
‚Ä¢	Si no existen los archivos del modelo, lo entrena.
    model = joblib.load(MODEL_FILENAME)
    scaler = joblib.load(SCALER_FILENAME)
    label_encoder = joblib.load(LABELENCODER_FILENAME)
‚Ä¢	Carga el modelo, el escalador y el codificador.
python
CopiarEditar
    audio = record_from_microphone(duration=DURATION, sr=SR)
    if audio is None:
        print("‚ùå Fall√≥ la grabaci√≥n. Saliendo.")
        return
‚Ä¢	Graba audio desde el micr√≥fono.
    sf.write("grabacion_temp.wav", audio, SR)
‚Ä¢	Guarda temporalmente el audio grabado.
    features = extract_features_from_array(audio, SR).reshape(1, -1)
    features_scaled = scaler.transform(features)
‚Ä¢	Extrae y normaliza los MFCC del audio grabado.
    y_prob = model.predict_proba(features_scaled)[0]
    y_pred = model.predict(features_scaled)[0]
    emotion_text = label_encoder.inverse_transform([y_pred])[0]
‚Ä¢	Predice la emoci√≥n y convierte el n√∫mero a texto.
    print("\nüé§ Resultado de la predicci√≥n:")
    for idx, emo in enumerate(label_encoder.classes_):
        print(f"   - {emo}: {y_prob[idx]*100:.2f}%")
    print(f"\n‚û° Emoci√≥n predicha: {emotion_text.upper()}")
‚Ä¢	Muestra las probabilidades de cada emoci√≥n y la predicci√≥n final.
________________________________________
SECCI√ìN 8: Men√∫ principal
if __name__ == "__main__":
‚Ä¢	Solo se ejecuta si el archivo se corre directamente (no si se importa como m√≥dulo).
    print("==============================================")
    print("   Clasificador de Emociones desde Voz")
    print("==============================================\n")
    print("Opciones:")
    print("  1) Entrenar / reentrenar el modelo con el dataset.")
    print("  2) Capturar audio desde micr√≥fono y predecir emoci√≥n.")
    print("  0) Salir.\n")
‚Ä¢	Imprime el men√∫ de opciones para el usuario.
    opcion = input("Selecciona una opci√≥n (0/1/2): ").strip()
‚Ä¢	Espera que el usuario seleccione una opci√≥n.
    if opcion == '1':
        train_and_save_model()
    elif opcion == '2':
        predict_emotion_from_microphone()
    else:
        print("üîö Saliendo...")
‚Ä¢	Ejecuta la funci√≥n correspondiente o sale del programa.










